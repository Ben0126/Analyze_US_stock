{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tensorflow 基本語法 ([網站](https://ithelp.ithome.com.tw/users/20119971/ironman/2254))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 數據類型\n",
    "\n",
    "​tensor在數學裡主要講的就是 “向量”，簡單來說就是一個n維度的data。 <br>\n",
    "主要支援資料格式就是一般的data type。包含: int , float , double , string , bool <br>\n",
    "\n",
    "所以我們要建立一個tf.tensor可以直接如下來建立tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.9.1'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=int32, numpy=6>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.constant(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=6.0>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.constant(6.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2,), dtype=bool, numpy=array([ True, False])>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.constant([True,False])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=string, numpy=b'I love TF2'>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.constant(\"I love TF2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 變數類型\n",
    "TF變數類型主要有三種，tf.constant、tf.Variable 以及 tf.placeholder。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**tf.constant:** <br>\n",
    "顧名思義，他就是一個constant的類別，你可以放入各式的資料型態，做一些基礎運算，Ex: tf.add 等等。 <br>\n",
    "使用時機像是有時候我們會放accuracy或者一些運算完的模型資訊等等。因此，在創建一些tf.constant的可以簡單的用上面語法或者是你假如有一個numpy array也可以直接使用 tf.convert_to_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create tf.constant\n",
    "a = tf.constant([1,2,3])\n",
    "# Convert np arry to tf\n",
    "a= np.array([1,2,3])\n",
    "b = tf.convert_to_tensor(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**tf.Variable** <br>\n",
    "簡單來說，tf.variable就是放置可學習的變數或者說將可求導的變數，例如: Neural Network的wieght或者bias。因此，在tf.variable中會紀錄他是learnable 或者在autograph中可被求導變數。之後，會實作簡單的一個NN會更清楚他的用途。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'Data_point:0' shape=(6,) dtype=float32, numpy=array([1., 1., 1., 1., 1., 1.], dtype=float32)>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create tf.Variable\n",
    "a = tf.ones(6)\n",
    "b = tf.Variable(a, name = 'Data_point')\n",
    "\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tf.float32"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b.dtype #check data tpye"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Data_point:0'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b.name #check name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b.trainable #check weather trainable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**tf.placeholder** <br>\n",
    "主要是TF在計算Gaph的方法。在使用時，我們是不會先給定一個初始值，而是給定長度或者資料格式先佔有一個空間。簡單來說就是，和Variable或者constant不一樣的是，不需給定初始值，但必須預先定義好資料類型與長寬深度。主要使用為在train模型，我們會放 x 與 y 的資料。在看TF1.X的程式會很常看到這個變數。在TF2.0中，已經不使用這個變數，蠻多都改成使用tf.data的api在導資料。而且在TF2.0中，在eager execution下，也不需要去預先定義這些資料空間。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 簡單建立資料\n",
    "有時候我們會想簡單建立有些都是0的資料，所以我們可以用一些簡單的TF語法來建立"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(6, 6), dtype=float32, numpy=\n",
       "array([[0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0.]], dtype=float32)>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Example create zero\n",
    "a = tf.zeros([6,6])\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(6, 6), dtype=float32, numpy=\n",
       "array([[0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0.]], dtype=float32)>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#or\n",
    "b = tf.zeros_like(a)\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(6, 6), dtype=int32, numpy=\n",
       "array([[0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0]])>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#or fill -> shape and fill nums\n",
    "c = tf.fill([6,6],0)\n",
    "c"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "建立一個random matrix，此時我們可以使用下面各式不同的distribution來建立。 <br>\n",
    "這樣的random方法我們常用於initial Deep learning中的weight或bias。 <br>\n",
    "因為，當你的weight不是random產生，而是一個齊一性的matrix，會讓您所學出來的權重都是一樣，網路會變成純粹的線性。 <br>\n",
    "\n",
    "**權重均必須random產生**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(6, 6), dtype=float32, numpy=\n",
       "array([[ 1.5988526 ,  0.1406798 , -0.30346355, -0.7026813 ,  0.5813478 ,\n",
       "         0.9994943 ],\n",
       "       [-0.45355526, -1.3237975 , -0.6967904 ,  0.78399515, -0.5458028 ,\n",
       "        -0.10231382],\n",
       "       [-0.7176008 , -1.2546759 ,  0.8180643 , -1.017536  ,  1.3700936 ,\n",
       "         0.8958166 ],\n",
       "       [-0.25636756, -0.9434931 , -0.07298949, -1.5354348 ,  2.062475  ,\n",
       "        -1.0037172 ],\n",
       "       [ 2.068513  , -0.2696432 , -0.6414222 , -1.4308274 , -1.1564838 ,\n",
       "        -0.45188615],\n",
       "       [ 0.21189198,  0.33802333, -1.1058456 ,  2.436304  , -2.223485  ,\n",
       "         0.5848353 ]], dtype=float32)>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Example random by normal distribution\n",
    "a = tf.random.normal([6,6],mean=0,stddev=1)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(6, 6), dtype=float32, numpy=\n",
       "array([[ 0.8571428 ,  1.3245986 ,  1.3602015 ,  1.7722728 ,  1.0745045 ,\n",
       "         0.16345483],\n",
       "       [ 0.24180356,  0.9247242 , -0.2823902 ,  1.1697292 ,  0.28993955,\n",
       "        -0.39261475],\n",
       "       [-0.77013093,  1.7253994 , -0.69616145, -0.8288765 , -0.33480766,\n",
       "        -0.41696244],\n",
       "       [-0.34874108, -0.36068428, -0.2794822 , -0.24372216, -0.61089283,\n",
       "         0.10393757],\n",
       "       [-1.4721991 , -0.778645  , -1.5918306 ,  1.3904209 , -0.16383505,\n",
       "        -1.3493391 ],\n",
       "       [-0.7558181 , -0.18061377, -1.4750434 ,  1.6862315 , -0.5099955 ,\n",
       "        -1.5525311 ]], dtype=float32)>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#random by truncated normal distribution\n",
    "b = tf.random.truncated_normal([6,6],mean=0,stddev=1)\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(6, 6), dtype=float32, numpy=\n",
       "array([[0.5571766 , 0.1095351 , 0.44586718, 0.7577535 , 0.42640913,\n",
       "        0.34921026],\n",
       "       [0.66029406, 0.44906235, 0.03302848, 0.40366983, 0.8328757 ,\n",
       "        0.04164398],\n",
       "       [0.26406515, 0.47387958, 0.03155053, 0.9853147 , 0.74855995,\n",
       "        0.96852183],\n",
       "       [0.7245778 , 0.0039351 , 0.21977198, 0.77969384, 0.21166825,\n",
       "        0.79275334],\n",
       "       [0.58730114, 0.26699448, 0.16617465, 0.131966  , 0.02241194,\n",
       "        0.9668703 ],\n",
       "       [0.7247833 , 0.3506304 , 0.13597906, 0.59281933, 0.5439019 ,\n",
       "        0.4334725 ]], dtype=float32)>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#random by uniform\n",
    "c = tf.random.uniform([6,6],minval=0,maxval=1)\n",
    "c"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 選取資料\n",
    "有時候，我們可能想將資料選取資料，看一下資料長什麼樣子。尤其是當我們想選出特定的row或者index該如何做呢？可以利用下面的語法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Example for select instance\n",
    "a = tf.ones([1,5,5,3])\n",
    "a[0][0].shape   #Output shape:TensorShape([5, 3])\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a[...,2].shape  #Output shape:TensorShape([1, 5, 5])\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reshape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "一般來說，以一個影像辨識的data shape，我們會將資料擺成 [batch, height(row), width(columns),channel] 。Ex: [128,64,64,1]。因次第一個說明的就是最常看到的reshape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "想資料轉換樣式，或者是把shape轉成我們想要的樣式 <br>\n",
    "Ex: [64,32,32] -> [64, 32*32]，將想是將一個image[b,h,w,3] 轉成 [b,pixcel,3]。類似將一個2維度的Matrix轉成一個1維度的array。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([6, 1024, 3])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Create samples\n",
    "a = tf.random.normal([6,32,32,3])\n",
    "\n",
    "#Reshape to different type\n",
    "tf.reshape(a,[6,32*32,3]).shape "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([6, 1024, 3])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 將reshape中的欄位設為-1，他會自動計算\n",
    "tf.reshape(a,[6,-1,3]).shape    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "一次使用兩次reshape來轉換資料"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([6, 16, 64, 3])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.reshape(tf.reshape(a,[6,-1]),[6,16,-1,3]).shape\n",
    "#Output:TensorShape([6, 16, 64, 3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transpose\n",
    "\n",
    "當你想要將matrix的欄位對調，Ex; [6,32,32,3] -> [6,32,3,32]，就可以使用transpose來對調。 <br>\n",
    "有時候會將[b,h,w,3] -> [b,3,h,w] (Pytorch格式)，就可以使用tf.transpose來轉。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([6, 32, 3, 32])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.transpose(a,perm=[0,1,3,2]).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Expand_dims\n",
    "當如果您想到增加一個維度，例如原本你有一個 [32,32,3]的圖，但您想新增新的一維度來記錄他的資料量，或者一個batch的量。就可以使用tf.expamd_dims來新增。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([1, 32, 32, 3])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = tf.random.normal([32,32,3])\n",
    "tf.expand_dims(a,axis=0).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Broadcasting\n",
    "Broadcast的function就是broadcast數值，但實際上，儲存或者variable size都是沒有變化，不會去複製data。 <br> \n",
    "因此，有較好的儲存效率。簡單的案例就像是我們在做Linear regression的時候，在 X*W+b的時候，通常b會以broadcast的方式來執行 (之後會有實作Linear regression)。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 概念: 當a 和 b 維度不一致時 (a=[4,32,32,3], b=[3])，做broadcast的時候，會先向右靠齊然後增加維度相加 (b會broadcast -> [3] -> [1,1,1,3] -> [4,32,32,3] 和a做運算)，也就是說他會exapand成相同的size。\n",
    "\n",
    "* 應用情境：今天公司有4個部們，40個員工，以及他們每個月的薪資，因為今天公司發大財，想要幫所有員工加薪，因此我們可能會組成一個matrix A = [4,40,12]，現在我們有另外一個每個月調薪的matrix B = [40,1]。這時候就可以用broadcast將所有人一次加薪，假如今天公司想要針對每個月加不一致的薪水，matrix B = [12]。\n",
    "\n",
    "(註: broadcast的時候，要對齊最右邊的那個維度，若非1，則必須相等)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([4, 40, 12])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = tf.random.normal([4,40,12])\n",
    "(x + tf.random.normal([40,1])).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "註1: 因為broadcast是一種內建的優化方式，TF會自斷判斷是否可以broadcast，不用特別寫broadcast <br>\n",
    "註2:假如你想broadcast且b的維度變成broadcast 後的相同維度，可以參考tf.broadcast_to 以及tf.tile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merge and Split\n",
    "假如我今天有兩個資料，想要以row wise的方式合併在一起，Ex: (#row,#cols) A[6,12] + B[6,12] = [12,12]。此時，可以使用tf.concat來合併資料。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([12, 32, 3])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = tf.ones([6,32,3])\n",
    "b = tf.ones([6,32,3])\n",
    "tf.concat([a,b],axis=0).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "此外，可以透過axis來調控你要合併by哪一個axis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([6, 64, 3])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = tf.ones([6,32,3])\n",
    "b = tf.ones([6,32,3])\n",
    "tf.concat([a,b],axis=1).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "假如我今天有兩個資料，想要以column wise的方式合併在一起，類似新增一個column，Ex: (#row,#cols) A[6,12] + B[6,12] = [2,6,12]。此時，可以使用tf.stack來合併資料。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([2, 6, 32, 3])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = tf.ones([6,32,3])\n",
    "b = tf.ones([6,32,3])\n",
    "tf.stack([a,b],axis=0).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split的話，這邊會比較unstack跟split的用法\n",
    "unstack與stack正好相反，也就是拿掉Column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = tf.ones([2,32,3])\n",
    "aa,ab= tf.unstack(a,axis=0)\n",
    "aa.shape\n",
    "#Output:TensorShape([32, 3])\n",
    "data_all = tf.unstack(a,axis=1)\n",
    "data_all[0].shape\n",
    "#Output:TensorShape([2, 3])\n",
    "len(data_all)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "split的話就會比較直觀，就是直接針對指定Column然後切幾分這樣。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_all = tf.split(a,axis=1,num_or_size_splits=2)\n",
    "data_all[0].shape\n",
    "#Output:TensorShape([2, 16, 3])\n",
    "len(data_all)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sort\n",
    "從字面來看就是排序，有時候需要透過sort來排序feature並針對排序後的資料來畫圖或者來檢驗您對資料的假設。 <br>\n",
    "又或者我今天講把預測不好的後100筆資料拿出來驗證模型模型問題。都可以使用這樣的方法。這邊會介紹兩種方法，一種是純粹的sort，一種是sort後output是index，你就可以拿index來針對特定feature畫圖。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(10,), dtype=float32, numpy=\n",
       "array([ 1.3792018 ,  0.7950544 ,  0.52371716,  0.3672976 ,  0.20072214,\n",
       "        0.15889104, -0.01921773, -0.5998441 , -1.1084162 , -1.945121  ],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Example for sort\n",
    "data = tf.random.normal([10],mean=0,stddev=1)\n",
    "tf.sort(data,direction='DESCENDING')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(10,), dtype=float32, numpy=\n",
       "array([-1.945121  , -1.1084162 , -0.5998441 , -0.01921773,  0.15889104,\n",
       "        0.20072214,  0.3672976 ,  0.52371716,  0.7950544 ,  1.3792018 ],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#or\n",
    "tf.gather(data,tf.argsort(data,direction='ASCENDING'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "拿top k 個就可以使用tf.math.top_k，他會同時return numer以及index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TopKV2(values=<tf.Tensor: shape=(5,), dtype=float32, numpy=\n",
       "array([1.3792018 , 0.7950544 , 0.52371716, 0.3672976 , 0.20072214],\n",
       "      dtype=float32)>, indices=<tf.Tensor: shape=(5,), dtype=int32, numpy=array([3, 9, 6, 1, 4])>)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Example top_k\n",
    "top_data = tf.math.top_k(data,5)\n",
    "top_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(5,), dtype=float32, numpy=\n",
       "array([1.3792018 , 0.7950544 , 0.52371716, 0.3672976 , 0.20072214],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_data.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Padding\n",
    "在做影像辨識的時候，有時候我們會做padding，而padding的作用是什麼呢？1. 針對差異圖片的大小做補齊，有時候可能輸入和filter不一致時，可以透過padding補齊。2. 有時候我們希望增加邊界訊息量，一般來說，沒做padding邊界只會被掃到一次，若做padding可以增加被掃到的次數，這邊簡單的說明padding及example，之後講CNN的時候會更詳細說明。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(5, 5), dtype=float32, numpy=\n",
       "array([[ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ],\n",
       "       [ 0.        ,  0.9941075 , -0.3805162 , -1.0929228 ,  0.        ],\n",
       "       [ 0.        , -0.32113233,  0.38333318, -0.13180594,  0.        ],\n",
       "       [ 0.        ,  0.06274855, -0.720729  ,  0.5564854 ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ]],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = tf.random.normal([3,3],mean=0,stddev=1)\n",
    "tf.pad(data,[[1,1],[1,1]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clipping\n",
    "做Deep learning計算gradient的時候，有時候會遇到gradient exploding。我們可預期當一個數字累乘 (1.01**100)，你的gradient會變超大。所以，解決的方法簡單來說就是超過一個門檻值就固定，或者重新使用tf.clip_by_norm，這個方法就比較進階一點，他是針對整個data做縮放"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 3), dtype=float32, numpy=\n",
       "array([[0.9941075 , 0.        , 0.        ],\n",
       "       [0.        , 0.38333318, 0.        ],\n",
       "       [0.06274855, 0.        , 0.5564854 ]], dtype=float32)>"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Example clipping\n",
    "tf.clip_by_value(data,0,1)\n",
    "#range if number less or above fix at 0 or 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 基本數學運算\n",
    "首先我們先從基本數學運算開始談起，這些運算您將會大量使用於DL or ML專案。雖然TF有很多已經寫好的實用function，但有時候可能還是無法達到一些客製化(老闆)需求，所以您可能還是需要自己寫function來運算一些指標或者修改loss function等等。接下來會討論一下基本運算。[ + - X % sqrt ...等等]，此外，運算時也要注意用法。\n",
    "\n",
    "*Element wise: 直接對相對應的元素相加，Ex: +- <br>\n",
    "*Matrix wise: 矩陣相乘，Ex: [6,32,4] @ [6,4,6] = [6,32,6] <br>\n",
    "*Dimention wise: 針對特定dimention做運算。Ex: 對整個dimention做reduce_mean。 <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(2, 2), dtype=int32, numpy=\n",
       " array([[11, 11],\n",
       "        [11, 11]])>,\n",
       " <tf.Tensor: shape=(2, 2), dtype=int32, numpy=\n",
       " array([[30, 30],\n",
       "        [30, 30]])>)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Example for element wise\n",
    "a = tf.fill([2,2],5)\n",
    "b = tf.fill([2,2],6)\n",
    "a+b,a*b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([2, 32, 6])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Example for Matrix wise\n",
    "a = tf.fill([2,32,4],5)\n",
    "b = tf.fill([2,4,6],6)\n",
    "(a@b).shape "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "以Dimension wise的來做sample，為來在算一些loss，或者計算accuracy會常用"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(), dtype=float32, numpy=0.071469165>,\n",
       " <tf.Tensor: shape=(40, 12), dtype=float32, numpy=\n",
       " array([[ 4.62767512e-01,  4.22995597e-01, -3.79276574e-01,\n",
       "          1.45967364e+00, -9.10601243e-02, -3.34578961e-01,\n",
       "         -1.12569138e-01, -4.54907179e-01,  1.32996514e-01,\n",
       "         -5.20453453e-01, -4.99596119e-01, -5.90019822e-01],\n",
       "        [ 1.54554874e-01, -6.11201078e-02,  7.81866789e-01,\n",
       "         -5.94453990e-01, -2.81887650e-02, -2.42647588e-01,\n",
       "         -3.03398520e-01,  2.88090497e-01, -2.57269472e-01,\n",
       "         -4.44746941e-01, -5.53212967e-03,  1.66807562e-01],\n",
       "        [ 2.38552570e-01,  1.12571454e+00, -6.60131335e-01,\n",
       "          1.87938988e-01,  9.82534438e-02,  6.84534490e-01,\n",
       "          4.70536441e-01,  4.72973406e-01,  1.89928591e-01,\n",
       "          6.38936937e-01, -9.84002650e-01, -9.90714550e-01],\n",
       "        [-3.52567345e-01,  7.71643519e-01,  1.71860963e-01,\n",
       "         -5.50930440e-01,  5.28669298e-01,  9.14733827e-01,\n",
       "         -4.33631063e-01,  1.35800242e-01,  7.95447454e-03,\n",
       "         -3.03332269e-01,  6.39431179e-02, -5.32175541e-01],\n",
       "        [-3.10572445e-01, -3.47005337e-01, -3.15479904e-01,\n",
       "         -8.81264448e-01,  2.08192021e-01, -5.00088215e-01,\n",
       "          8.06286931e-01,  4.22105670e-01, -3.46553206e-01,\n",
       "          4.23663139e-01,  7.85696864e-01,  8.10712755e-01],\n",
       "        [ 1.93534732e-01, -8.98209810e-01,  3.96667272e-02,\n",
       "         -7.42147088e-01, -2.79845744e-01,  5.60888886e-01,\n",
       "          9.45675313e-01,  1.93554014e-01, -1.25430822e-02,\n",
       "          2.50342816e-01, -8.88681710e-02,  6.37736022e-01],\n",
       "        [ 1.19567484e-01,  6.92312598e-01,  2.47085482e-01,\n",
       "         -1.20806657e-01, -4.37930971e-02, -2.04547942e-01,\n",
       "         -4.94547069e-01,  7.08174407e-02,  4.33092952e-01,\n",
       "          7.30162024e-01, -2.85743307e-02,  1.82711035e-02],\n",
       "        [ 8.09571147e-01, -4.32563722e-02,  5.44955075e-01,\n",
       "         -7.49072731e-01,  9.86295402e-01,  3.07753384e-01,\n",
       "          8.68988708e-02,  7.73444921e-02, -2.29130000e-01,\n",
       "          4.66816217e-01,  1.03437893e-01, -4.52007353e-02],\n",
       "        [ 1.95553452e-02,  5.00600696e-01,  3.05361658e-01,\n",
       "          5.14935672e-01,  1.28757209e-01,  5.41910052e-01,\n",
       "          6.70507252e-02,  1.19484615e+00,  7.40743041e-01,\n",
       "         -5.33375680e-01,  3.91775608e-01,  5.71479321e-01],\n",
       "        [-6.34855449e-01, -4.74452525e-01,  2.73554921e-01,\n",
       "         -6.24324441e-01, -2.67431676e-01, -2.21624166e-01,\n",
       "         -5.84143877e-01,  5.42225718e-01, -8.59798491e-02,\n",
       "         -4.04965460e-01, -1.18701363e+00, -1.27191350e-01],\n",
       "        [ 4.91710007e-01,  1.82532087e-01, -5.95463276e-01,\n",
       "         -5.81040740e-01,  3.30162942e-01, -4.71491396e-01,\n",
       "         -3.66877526e-01, -4.69498709e-03,  3.72044146e-01,\n",
       "         -7.06516981e-01,  3.63377810e-01, -4.74645823e-01],\n",
       "        [ 9.84499305e-02,  5.48840128e-02,  4.89060909e-01,\n",
       "          5.96553445e-01,  9.02223766e-01, -6.28119946e-01,\n",
       "         -9.11590233e-02,  2.71920264e-01, -2.77607262e-01,\n",
       "          1.32723022e+00,  4.54355121e-01,  2.29504585e-01],\n",
       "        [ 1.42280710e+00, -1.68342143e-01, -7.33370662e-01,\n",
       "          2.07961649e-01, -4.61536646e-01, -4.71342504e-02,\n",
       "          2.76780501e-03,  5.80598950e-01,  3.22209150e-01,\n",
       "         -2.29979545e-01, -1.65394321e-01, -5.90230823e-01],\n",
       "        [-1.13120079e-02,  5.97561300e-01,  1.88079327e-02,\n",
       "          4.76666391e-01, -3.02697659e-01,  4.05658424e-01,\n",
       "          6.70964122e-01,  6.62442505e-01,  4.28418517e-01,\n",
       "         -8.11037183e-01, -2.03996122e-01,  5.74015319e-01],\n",
       "        [-8.88578773e-01,  4.93783981e-01, -3.89324486e-01,\n",
       "         -6.42623127e-01,  4.80661511e-01, -7.30007887e-04,\n",
       "          2.10422277e-02, -2.63943821e-01, -6.53408766e-01,\n",
       "         -4.90755439e-01, -7.60930240e-01,  6.91625297e-01],\n",
       "        [-1.81347683e-01,  4.30716515e-01,  3.92885864e-01,\n",
       "         -1.09704375e+00,  6.76967859e-01, -2.66192168e-01,\n",
       "          7.58723736e-01, -4.34288412e-01,  8.34948123e-01,\n",
       "          3.18773478e-01,  4.42372739e-01,  5.74106932e-01],\n",
       "        [ 4.32923794e-01, -3.48821580e-02, -8.15120578e-01,\n",
       "         -1.47505224e-01, -7.88233876e-01, -1.09154060e-02,\n",
       "          8.65483806e-02,  1.58073708e-01,  6.37129128e-01,\n",
       "          4.49797422e-01, -9.01745632e-02,  1.76194739e+00],\n",
       "        [-2.57978067e-02,  8.16671073e-01,  3.72998454e-02,\n",
       "          2.38076746e-01, -5.05734861e-01, -2.47662783e-01,\n",
       "         -4.89895284e-01,  4.85335261e-01,  1.43995836e-01,\n",
       "         -5.18874824e-01,  3.14655066e-01, -6.23444080e-01],\n",
       "        [-1.58675283e-01,  3.23682606e-01,  8.98548365e-02,\n",
       "          1.00161374e+00,  1.16566725e-01, -5.46476603e-01,\n",
       "          6.04816198e-01,  3.83722901e-01,  3.54055703e-01,\n",
       "         -1.35125726e-01,  3.75696003e-01,  1.29268065e-01],\n",
       "        [-3.13113272e-01, -8.39004517e-02,  6.82618618e-02,\n",
       "         -6.91394657e-02,  4.75335121e-03, -1.26844943e-01,\n",
       "         -7.23723531e-01, -5.82314551e-01,  5.03142625e-02,\n",
       "          3.43117207e-01,  1.00104904e+00,  7.66246319e-01],\n",
       "        [-1.32035792e-01,  1.32264733e+00,  6.90154672e-01,\n",
       "          1.13094032e-01,  1.15837932e-01,  1.02211964e+00,\n",
       "         -4.36220795e-01, -9.59478855e-01, -9.01072621e-01,\n",
       "          3.67782474e-01, -3.21767986e-01,  5.56595445e-01],\n",
       "        [ 1.07508004e+00,  8.49154353e-01, -2.38187611e-03,\n",
       "          2.18730688e-01, -1.56047568e-01,  1.06394172e-01,\n",
       "         -3.09249699e-01,  3.65495890e-01,  9.37566936e-01,\n",
       "          5.13333380e-01,  4.18959439e-01,  6.79338872e-01],\n",
       "        [-2.72563100e-01,  5.18688858e-01,  3.85853648e-01,\n",
       "          1.02368426e+00, -3.57272208e-01, -6.53988481e-01,\n",
       "         -1.26710665e+00, -9.60291386e-01,  6.14494011e-02,\n",
       "          1.01629937e+00,  1.72756910e-01,  2.08657384e-01],\n",
       "        [ 6.09435201e-01,  3.46402884e-01, -8.95019054e-01,\n",
       "          6.05035722e-01,  2.42425948e-01, -1.16863990e+00,\n",
       "         -5.52730739e-01, -7.21219718e-01,  2.40638465e-01,\n",
       "          1.17143273e+00, -9.05212760e-02, -1.58011049e-01],\n",
       "        [-5.70833027e-01,  5.27069092e-01, -1.26870260e-01,\n",
       "          1.54276937e-02, -1.32372057e+00,  1.14708550e-01,\n",
       "          3.47307503e-01,  9.17992711e-01, -3.77527237e-01,\n",
       "         -3.86167914e-01,  8.59556198e-01,  3.26188445e-01],\n",
       "        [ 6.13694787e-01, -5.07918298e-01, -5.06336987e-03,\n",
       "         -8.02802324e-01,  3.26230526e-02, -9.39828753e-01,\n",
       "          6.84242249e-02, -6.44544065e-01,  5.79000711e-01,\n",
       "          1.37149990e-01,  4.57016826e-02, -1.22928619e-03],\n",
       "        [ 1.88719884e-01, -3.76818150e-01, -2.45668530e-01,\n",
       "         -1.38342336e-01,  6.85860276e-01,  2.50806391e-01,\n",
       "          1.11866526e-01, -1.91547543e-01,  1.31147027e-01,\n",
       "         -1.08963120e+00, -5.62063992e-01,  2.41727531e-02],\n",
       "        [-1.77294046e-01, -2.23354399e-01, -2.68938601e-01,\n",
       "          2.51070857e-01, -4.45569992e-01,  4.06561613e-01,\n",
       "          2.97204792e-01,  8.49218518e-02,  3.71342242e-01,\n",
       "         -3.24877769e-01,  3.37842524e-01, -1.94841921e-02],\n",
       "        [-3.86894763e-01,  3.82579803e-01,  7.79065907e-01,\n",
       "          6.31165653e-02,  4.96657267e-02, -2.82896668e-01,\n",
       "          7.41269886e-01, -2.78603375e-01, -1.71661496e-01,\n",
       "         -1.33029088e-01,  9.73189712e-01,  1.21667996e-01],\n",
       "        [-2.10495561e-01,  6.98672593e-01,  1.56355590e-01,\n",
       "          7.54789561e-02,  1.87197506e-01,  6.96456671e-01,\n",
       "          5.71930707e-01,  7.18334019e-02, -4.81114656e-01,\n",
       "         -3.96002859e-01, -1.75510123e-02,  3.37063909e-01],\n",
       "        [ 2.89000720e-01,  6.13448381e-01,  3.33631843e-01,\n",
       "          8.46842676e-02,  9.99836564e-01,  6.23346567e-01,\n",
       "          8.27976912e-02, -5.12354195e-01, -3.81813914e-01,\n",
       "         -5.82366645e-01,  1.43969327e-01,  7.79345185e-02],\n",
       "        [-1.89446792e-01, -5.55030107e-01,  4.31402624e-02,\n",
       "         -3.82895142e-01,  6.22292876e-01,  1.44338578e-01,\n",
       "          2.37650007e-01,  4.11847323e-01, -3.58994305e-02,\n",
       "         -4.82689381e-01,  1.06656563e+00, -2.51709998e-01],\n",
       "        [-5.65051794e-01,  8.12648237e-01,  1.81271225e-01,\n",
       "         -9.80635166e-01,  4.11909848e-01, -1.97237119e-01,\n",
       "         -1.66497231e-01, -3.13371480e-01, -1.81107134e-01,\n",
       "          7.26916134e-01,  3.00769478e-01, -9.27545801e-02],\n",
       "        [-1.23242468e-01,  5.85250497e-01, -8.79133642e-02,\n",
       "          4.83658127e-02,  1.86433852e-01,  1.52855411e-01,\n",
       "          8.30966771e-01,  7.92766511e-02,  2.09683627e-01,\n",
       "          2.87183672e-01,  5.67507565e-01,  9.17826533e-01],\n",
       "        [ 3.09393674e-01, -1.43790141e-01, -1.64056718e-02,\n",
       "          2.98648119e-01,  1.69710726e-01,  1.11255020e-01,\n",
       "          4.86649871e-01, -6.83386326e-01,  6.20527089e-01,\n",
       "          2.48455852e-01,  4.54562396e-01,  4.08307403e-01],\n",
       "        [ 1.74150541e-01, -5.53320765e-01, -5.44911027e-01,\n",
       "          4.06693220e-01,  2.85584852e-02,  2.28589043e-01,\n",
       "          6.65406227e-01,  8.42424035e-02,  2.39762843e-01,\n",
       "          1.69920594e-01,  8.13585401e-01,  1.94263384e-01],\n",
       "        [-4.77559865e-01, -1.06130645e-01, -3.27175498e-01,\n",
       "          7.81066060e-01, -5.02936691e-02,  3.00793171e-01,\n",
       "         -2.21253112e-01,  1.95168287e-01, -5.22468865e-01,\n",
       "         -7.12100208e-01, -1.60968140e-01,  3.60136777e-01],\n",
       "        [-3.02244335e-01, -9.20694768e-02, -2.16641888e-01,\n",
       "         -3.68072152e-01, -2.77900130e-01,  4.72794443e-01,\n",
       "          1.05121143e-01, -8.51721883e-01,  2.30544955e-01,\n",
       "         -7.98368454e-02,  4.84475940e-01, -5.46946287e-01],\n",
       "        [ 2.89187610e-01, -9.02737379e-01, -4.14909124e-01,\n",
       "          2.53993273e-01,  1.19233236e-01,  2.65391171e-01,\n",
       "          5.84675074e-01,  7.13067055e-02,  7.67849147e-01,\n",
       "         -1.67962387e-01,  6.63142920e-01, -5.72000027e-01],\n",
       "        [ 5.86298347e-01,  4.92816195e-02,  2.74436384e-01,\n",
       "         -2.01237351e-01,  2.38714263e-01, -4.91326451e-02,\n",
       "          2.80948222e-01,  7.89906263e-01,  7.12124765e-01,\n",
       "         -2.48583555e-01,  8.08404535e-02,  3.12132061e-01]], dtype=float32)>,\n",
       " <tf.Tensor: shape=(4, 12), dtype=float32, numpy=\n",
       " array([[-1.39848039e-01,  2.69296944e-01,  2.43998647e-01,\n",
       "         -9.45477858e-02,  1.27956912e-01, -2.70410866e-01,\n",
       "          1.41246110e-01, -1.60198167e-01,  9.66445953e-02,\n",
       "          6.86356574e-02, -2.80716121e-02,  1.92861900e-01],\n",
       "        [-2.21370265e-01,  5.88135943e-02, -1.04382515e-01,\n",
       "          2.44802646e-02,  6.81300610e-02,  7.51839280e-02,\n",
       "          1.02934256e-01,  8.47368240e-02,  8.31208676e-02,\n",
       "          1.02240190e-01,  1.29983976e-01,  1.17127791e-01],\n",
       "        [ 2.55583376e-01,  1.02488235e-01,  1.47701964e-01,\n",
       "          2.07140878e-01, -5.12302108e-02,  2.05482811e-01,\n",
       "         -2.55594440e-02,  3.27885538e-01,  2.83636361e-01,\n",
       "         -1.82741180e-01,  3.12643647e-01,  1.87058195e-01],\n",
       "        [ 3.35082293e-01,  3.24061602e-01, -3.60881418e-01,\n",
       "         -2.12256074e-01,  1.72390953e-01,  1.06855229e-01,\n",
       "          1.19431615e-01, -1.36906609e-01,  2.00292543e-02,\n",
       "          3.55600758e-04,  2.36726999e-01,  8.69768411e-02]], dtype=float32)>)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Example for dimension wise\n",
    "data = [[1,2,3],\n",
    "      [1,2,3]]\n",
    "\n",
    "tf_data = tf.cast(x,tf.float32)\n",
    "\n",
    "mean_all = tf.reduce_mean(tf_data, keepdims=False)\n",
    "mean_0 = tf.reduce_mean(tf_data, axis=0, keepdims=False)\n",
    "mean_1 = tf.reduce_mean(tf_data, axis=1, keepdims=False)\n",
    "\n",
    "mean_all,mean_0,mean_1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "可以清楚的看到他會去計算by你所設定的axis，針對特定axis計算mean。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('Learning_PY')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c7f2880d10652d500a9c722ddc310138401d72ab0e68831a21dda226a38dfc4d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
